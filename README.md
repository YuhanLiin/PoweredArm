### Current state of this repo:

PyoManager library is used to collect EMG data from the Myo, which is connected to the Raspberry Pi via bluetooth.

There are currently two convenience scripts available. The **train\_svm** script aggregates all csv files produced by the training phase of the Myo script into a linear classifier file. The **use\_svm** scripts applies a linear classifier onto a file of sample EMG data and prints out the gesture predicted for each row. Both scripts must be invoked from the /poweredarm directory as such:

`python -m ml.train_svm [training_data_dir] [linear_classifier_name]` 
* **training\_data\_dir:** The directory to search for the csv training data, relative to /poweredarm/data. Default is EMG\_Training\_Data.
* **linear\_classifier\_name:** The filename of the classifier generated by this script. Default is linear\_classifier\_1.csv.

`python -m ml.use_svm [sample_filename] [linear_classifier_name]`
* **sample\_filename:** The name of the csv file containing the sample EMG data for the prediction. Must be placed inside poweredarm/data/Sample\_Prediction\_Data. Default is sample.csv.
* **linear\_classifier\_name:** The filename of the classifier used for this prediction. Default is linear\_classifier\_1.csv.

Note that if only one argument is provided, then it will go to the first argument while the second argument uses the default.

To make sample data, call `python -m helpers.make_sample [training_path] [sample_name]`
* **training\_path:** The path, relative to /poweredarm, to the training csv data we wish to convert to sample data.
* **sample\_name:** Name of the sample file to create. The same argument can be passed into use\_svm. Default is sample.csv.

### Gesture recognition is split into two PyoConnect tasks: training and prediction.

In the __training__ stage, the script is modified so that it simply reads the EMG data and writes it to a file. Before collecting the data, the tester and the user must agree on a gesture to perform. The tester then sets the variable `gesture` in the PyoManager training script to said gesture, the user performs said gesture, and the tester runs the program to collect samples.
The samples will be written to timestamped CSV files, with the first 8 columns representing the emg data as floats and the final column will be an integer representing the gesture being performed. Run the `train_svm` script afterwards (no arguments) to create a linear classifier from the collected data.


In the __prediction__ stage, a classifier is loaded from file using the `fromFile()` method. It can then be inserted into the PyoManager predicting script, which accepts new emg data from the Myo and can return its prediction as to the associated gesture.

To run PyoConnect, go into /poweredarm and run `python PyoManager.pyc` (sudo may be required to access the serial port). Then enable either one of the options and press Connect Myo to get started. If an option cannot be turned on, its corresponding script is likely invalid. An easy way to debug this is to call the script directly via `python -m scripts.<name_of_script>`.

## RPi Usage
### Connecting to the Pi
These instructions pertain to my Ubuntu 18.04 laptop and Marc's Pi 3 Model B, though I will try to provide instructions for a brand new Pi as well. An Ethernet port and cable are required. The result is a headless connection to the Pi that operates without connecting a separate monitor or keyboard.
1. Power on the Pi and connect it to the laptop with an Ethernet cable.
2. Install (sudo apt) nm-connection-editor and run it (on older versions of Ubuntu you can click the connection icon on the top right of the screen instead).
3. Double-click "Wired Connection 1", go to "IPv4 Settings", and change the Method to "Shared to other Computers". Apply changes.
4. Enter "cat /var/lib/misc/dnsmasq.leases" to get the IP address of the Pi.
5. Enter "ssh pi@<ip-address>" to establish SSH connection. The default password should be **raspberry**, though on Marc's pi it's **poweredarm**.
6. In SSH you can access the Pi's entire filesystem. On Marc's Pi the repo is cloned at /home/pi/BioTron/PoweredArm, which contains a git repo with the origin pointing to my Github repo. Pull to get the latest version. On a new Pi you will have to clone the repo yourself.

### VNC connection
This is necessary because with the Myo framework we have right now, it is not possible to run the Gesture recognition without the UI. In the future we hope to run all the code from SSH alone.
1. Download VNC viewer on your laptop.
2. SSH into the Pi and install realvnc-vnc-server.
3. Enter "vncserver" on the Pi to start the VNC server. There should be a line at the bottom with "New desktop is raspberrypi:<some-number>". The number is the VNC virtual screen number. You will need to do this for every reboot.
4. Open VNC viewer and type in <ip-address>:<screen-number> (10.42.0.162:2, for example). You will be prompted to enter a username and password. The username is **pi** and the password is the same for SSH. Now you can access the Pi's desktop UI from your laptop.

## PocketBeagle Usage
### Connecting to the PocketBeagle
The PocketBeagle allows connection via USB-to-microUSB and is capable of Internet connection and can drive servos and run the above machine-learning scripts. It has no BLE, so it can't connect to the Myo. The below instructions apply to my PocketBeagle.
1. Connect the Beagle to a laptop.
2. Establish SSH connection with something like "ssh" or PUTTY. Address is debian@192.168.6.2 or debian@192.168.7.2. Password is "temppwd".
3. Once you're in the Beagle, type "cd PoweredArm/poweredarm/mechanics" to go to that directory. Then type "python servo.py" to run the servo testing script.

To change the code on the Beagle, you can either edit directly with vim (the .vimrc file has my own bindings, so feel free to change them) or change your local copy of the code, commit it to GitHub, then call "git pull" on the Beagle. To do so, your GitHub account needs to be a collaborator on the repo (ask me and I'll add you) and you need to change the git user on the Beagle to yourself. Type:
* git config --global user.name "\<Your name\>"
* git config --global user.email "\<Your email\>"
Alternatively, you can also copy the changed files from your computer onto the board through the USB connection with a command like "scp".

### PocketBeagle Wiring and Servo Usage
The pin setup for the PocketBeagle is shown below.
![Pin setup](https://www.element14.com/community/servlet/JiveServlet/showImage/105-117543-480592/PocketBeagle_pinout.png)
Note that the layout assumes the Beagle is laying with its USB port at the top. To connect servos, connect red and brown wires to the 3.3V and GND pins respectively (These 2 can be shared amongst multiple servos). The orange wire must be connected to one of the PWM pins. The mapping between the Beagle pin # and the PWM # used by the servo script is as such:
* P1_36 = PWM 0
* P1_33 = PWM 1
* P2_01 = PWM 2
* P2_03 = PWM 3

### Issues
The emg data produced by the myo_raw library we're currently using is not compatible with myo emg data produced from outside sources, such as MyoConnect. As such all sample data must be produced from this repo. A fix for this is in progress on the new-emg-format branch. **(Not important right now)**

Key grip sometimes is mistaken for open hand.

