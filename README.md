# Beowulf-EMG-Classification
Gesture Classification Algorithms

### Current state of this repo:

PyoManager library is used to collect EMG data from the Myo, which is connected to the Raspberry Pi via bluetooth.

There are currently two convenience scripts available. The **train\_svm** script aggregates all csv files produced by the training phase of the Myo script into a linear classifier file. The **use\_svm** scripts applies a linear classifier onto a file of sample EMG data and prints out the gesture predicted for each row. Both scripts must be invoked from the /poweredarm directory as such:

`python -m ml.train_svm [training_data_dir] [linear_classifier_name]` 
* **training\_data\_dir:** The directory to search for the csv training data, relative to /poweredarm/data. Default is EMG\_Training\_Data.
* **linear\_classifier\_name:** The filename of the classifier generated by this script. Default is linear\_classifier\_1.csv.

`python -m ml.use_svm [sample_filename] [linear_classifier_name]`
* **sample\_filename:** The name of the csv file containing the sample EMG data for the prediction. Must be placed inside poweredarm/data/Sample\_Prediction\_Data. Default is sample.csv.
* **linear\_classifier\_name:** The filename of the classifier used for this prediction. Default is linear\_classifier\_1.csv.

Note that if only one argument is provided, then it will go to the first argument while the second argument uses the default.

To make sample data, call `python -m helpers.make_sample [training_path] [sample_name]`
* **training\_path:** The path, relative to /poweredarm, to the training csv data we wish to convert to sample data.
* **sample\_name:** Name of the sample file to create. The same argument can be passed into use\_svm. Default is sample.csv.
**
### Gesture recognition is split into two PyoConnect tasks: training and prediction.

In the __training__ stage, the script is modified so that it simply reads the EMG data and writes it to a file. Before collecting the data, the tester and the user must agree on a gesture to perform. The tester then sets the variable `gesture` in the PyoManager training script to said gesture, the user performs said gesture, and the tester runs the program to collect samples.
The samples will be written to timestamped CSV files, with the first 8 columns representing the emg data as floats and the final column will be an integer representing the gesture being performed. Run the `train_svm` script afterwards (no arguments) to create a linear classifier from the collected data.


In the __prediction__ stage, a classifier is loaded from file using the `fromFile()` method. It can then be inserted into the PyoManager predicting script, which accepts new emg data from the Myo and can return its prediction as to the associated gesture.

To run PyoConnect, go into /poweredarm and run `python PyoManager.pyc` (sudo may be required to access the serial port). Then enable either one of the options and press Connect Myo to get started. If an option cannot be turned on, its corresponding script is likely invalid. An easy way to debug this is to call the script directly via `python -m scripts.<name_of_script>`.

### Issues
The emg data produced by the myo/_raw library we're currently using is not compatible with myo emg data produced from outside sources, such as MyoConnect. As such all sample data must be produced from this repo. A fix for this is in progress on the new-emg-format branch. **Not important right now**

